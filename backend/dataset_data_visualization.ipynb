{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa92e7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('./data/yelp_dataset_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f008e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9859c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['legit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfb8af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_in_fake = dataset[(dataset['legit'] == False)]['positive'].mean()\n",
    "negative_in_fake = dataset[(dataset['legit'] == False)]['negative'].mean()\n",
    "neutral_in_fake = dataset[(dataset['legit'] == False)]['neutral'].mean()\n",
    "print(f\"Average sentiment scores in fake reviews - Positive: {positive_in_fake}, Negative: {negative_in_fake}, Neutral: {neutral_in_fake}\")\n",
    "\n",
    "positive_in_legit = dataset[(dataset['legit'] == True)]['positive'].mean()\n",
    "negative_in_legit = dataset[(dataset['legit'] == True)]['negative'].mean()      \n",
    "neutral_in_legit = dataset[(dataset['legit'] == True)]['neutral'].mean()\n",
    "print(f\"Average sentiment scores in legit reviews - Positive: {positive_in_legit}, Negative: {negative_in_legit}, Neutral: {neutral_in_legit}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260bb40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = 'Positive', 'Neutral', 'Negative'\n",
    "sizes_fake = [positive_in_fake, neutral_in_fake, negative_in_fake]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(sizes_fake, labels=labels, autopct='%1.1f%%')\n",
    "ax.set_title('Sentiment Distribution in Fake Reviews')\n",
    "\n",
    "sizes_legit = [positive_in_legit, neutral_in_legit, negative_in_legit]\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(sizes_legit, labels=labels, autopct='%1.1f%%')\n",
    "ax.set_title('Sentiment Distribution in Legit Reviews')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8db856",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratigs_fake = dataset[(dataset['legit'] == False)]['rating'].value_counts().sort_index()\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(ratigs_fake.index, ratigs_fake.values)\n",
    "ax.set_xlabel('Rating Fake')\n",
    "ax.set_ylabel('Number of Reviews')\n",
    "\n",
    "ratings_legit = dataset[(dataset['legit'] == True)]['rating'].value_counts().sort_index()\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(ratings_legit.index, ratings_legit.values)\n",
    "ax.set_xlabel('Rating Legit')\n",
    "ax.set_ylabel('Number of Reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda27ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Statistics for bot scores in fake reviews:\")\n",
    "print(dataset[dataset['legit'] == False]['bot'].describe())\n",
    "print(\"Statistics for no_bot scores in fake reviews:\")\n",
    "dataset[dataset['legit'] == False]['no_bot'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16871e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Statistics for bot scores in legit reviews:\")\n",
    "print(dataset[dataset['legit'] == True]['bot'].describe())\n",
    "print(\"Statistics for no_bot scores in legit reviews:\")\n",
    "dataset[dataset['legit'] == True]['no_bot'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c91a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Statistics for spam scores in fake reviews:\")\n",
    "print(dataset[dataset['legit'] == False]['spam'].describe())\n",
    "print(\"Statistics for no_spam scores in fake reviews:\") \n",
    "dataset[dataset['legit'] == False]['no_spam'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65da08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Statistics for spam scores in legit reviews:\")\n",
    "print(dataset[dataset['legit'] == True]['spam'].describe())\n",
    "print(\"Statistics for no_spam scores in legit reviews:\")\n",
    "dataset[dataset['legit'] == True]['no_spam'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36462f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Statistics for subjectivity in fake reviews:\")\n",
    "print(dataset[dataset['legit'] == False]['subjectivity'].describe())\n",
    "print(\"Statistics for subjectivity in legit reviews:\")\n",
    "dataset[dataset['legit'] == True]['subjectivity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fef710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute review lengths (characters) and word counts, then print means for fake vs legit\n",
    "dataset['char_len'] = dataset['review'].str.len()\n",
    "dataset['word_count'] = dataset['review'].str.split().str.len()\n",
    "\n",
    "mean_char_fake = dataset.loc[dataset['legit'] == False, 'char_len'].mean()\n",
    "mean_char_legit = dataset.loc[dataset['legit'] == True, 'char_len'].mean()\n",
    "mean_words_fake = dataset.loc[dataset['legit'] == False, 'word_count'].mean()\n",
    "mean_words_legit = dataset.loc[dataset['legit'] == True, 'word_count'].mean()\n",
    "\n",
    "print(f\"Mean review length (chars) - Fake: {mean_char_fake:.1f}, Legit: {mean_char_legit:.1f}\")\n",
    "print(f\"Mean review length (words) - Fake: {mean_words_fake:.1f}, Legit: {mean_words_legit:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5105318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot_with_outliers_legit_review_length = dataset[dataset['legit'] == True]['word_count']\n",
    "box_plot_with_outliers_fake_review_length = dataset[dataset['legit'] == False]['word_count']\n",
    "data_to_plot = [box_plot_with_outliers_legit_review_length, box_plot_with_outliers_fake_review_length]\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(data_to_plot, tick_labels=['Legit Reviews', 'Fake Reviews'])\n",
    "ax.set_title('Review Lengths (Word Count) Distribution')\n",
    "ax.set_ylabel('Word Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6239bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_review_sentence_lenght_char = dataset[dataset['legit'] == False]['char_len']\n",
    "legit_review_sentence_lenght_char = dataset[dataset['legit'] == True]['char_len']\n",
    "data_to_plot_char = [legit_review_sentence_lenght_char, fake_review_sentence_lenght_char]\n",
    "fig, ax = plt.subplots()            \n",
    "ax.boxplot(data_to_plot_char, tick_labels=['Legit Reviews', 'Fake Reviews'])\n",
    "ax.set_title('Review Lengths (Character Count) Distribution')\n",
    "ax.set_ylabel('Character Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6292bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add average word length per review (characters per word)\n",
    "dataset['avg_word_length'] = dataset['char_len'] / dataset['word_count'].replace(0, pd.NA)\n",
    "\n",
    "# ensure key columns are present and keep all existing features as well\n",
    "base_cols = ['id_review', 'review', 'legit', 'char_len', 'word_count', 'avg_word_length']\n",
    "base_cols = [c for c in base_cols if c in dataset.columns]\n",
    "# keep base columns first, then any remaining feature columns\n",
    "other_cols = [c for c in dataset.columns if c not in base_cols]\n",
    "features_df = dataset[base_cols + other_cols]\n",
    "\n",
    "# save extracted features to a new CSV\n",
    "features_path = './data/yelp_reviews_extracted_features.csv'\n",
    "features_df.to_csv(features_path, index=False)\n",
    "\n",
    "# merge with existing features file from the other notebook on id_review\n",
    "other_path = './data/yelp_reviews_with_features.csv'\n",
    "other_df = pd.read_csv(other_path)\n",
    "\n",
    "merged_df = pd.merge(other_df, features_df, on='id_review', how='inner', validate=\"many_to_many\")\n",
    "merged_path = './data/yelp_reviews_merged_features.csv'\n",
    "merged_df.to_csv(merged_path, index=False)\n",
    "\n",
    "features_path, merged_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
