{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa92e7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('./data/yelp_dataset_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f008e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9859c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['legit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfb8af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_in_fake = dataset[(dataset['legit'] == False)]['positive'].mean()\n",
    "negative_in_fake = dataset[(dataset['legit'] == False)]['negative'].mean()\n",
    "neutral_in_fake = dataset[(dataset['legit'] == False)]['neutral'].mean()\n",
    "print(f\"Average sentiment scores in fake reviews - Positive: {positive_in_fake}, Negative: {negative_in_fake}, Neutral: {neutral_in_fake}\")\n",
    "\n",
    "positive_in_legit = dataset[(dataset['legit'] == True)]['positive'].mean()\n",
    "negative_in_legit = dataset[(dataset['legit'] == True)]['negative'].mean()      \n",
    "neutral_in_legit = dataset[(dataset['legit'] == True)]['neutral'].mean()\n",
    "print(f\"Average sentiment scores in legit reviews - Positive: {positive_in_legit}, Negative: {negative_in_legit}, Neutral: {neutral_in_legit}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260bb40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = 'Positive', 'Neutral', 'Negative'\n",
    "sizes_fake = [positive_in_fake, neutral_in_fake, negative_in_fake]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(sizes_fake, labels=labels, autopct='%1.1f%%')\n",
    "ax.set_title('Sentiment Distribution in Fake Reviews')\n",
    "\n",
    "sizes_legit = [positive_in_legit, neutral_in_legit, negative_in_legit]\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(sizes_legit, labels=labels, autopct='%1.1f%%')\n",
    "ax.set_title('Sentiment Distribution in Legit Reviews')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8db856",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratigs_fake = dataset[(dataset['legit'] == False)]['rating'].value_counts().sort_index()\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(ratigs_fake.index, ratigs_fake.values)\n",
    "ax.set_xlabel('Rating Fake')\n",
    "ax.set_ylabel('Number of Reviews')\n",
    "\n",
    "ratings_legit = dataset[(dataset['legit'] == True)]['rating'].value_counts().sort_index()\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(ratings_legit.index, ratings_legit.values)\n",
    "ax.set_xlabel('Rating Legit')\n",
    "ax.set_ylabel('Number of Reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda27ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Statistics for bot scores in fake reviews:\")\n",
    "print(dataset[dataset['legit'] == False]['bot'].describe())\n",
    "print(\"Statistics for no_bot scores in fake reviews:\")\n",
    "dataset[dataset['legit'] == False]['no_bot'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16871e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Statistics for bot scores in legit reviews:\")\n",
    "print(dataset[dataset['legit'] == True]['bot'].describe())\n",
    "print(\"Statistics for no_bot scores in legit reviews:\")\n",
    "dataset[dataset['legit'] == True]['no_bot'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c91a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Statistics for spam scores in fake reviews:\")\n",
    "print(dataset[dataset['legit'] == False]['spam'].describe())\n",
    "print(\"Statistics for no_spam scores in fake reviews:\") \n",
    "dataset[dataset['legit'] == False]['no_spam'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65da08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Statistics for spam scores in legit reviews:\")\n",
    "print(dataset[dataset['legit'] == True]['spam'].describe())\n",
    "print(\"Statistics for no_spam scores in legit reviews:\")\n",
    "dataset[dataset['legit'] == True]['no_spam'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36462f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Statistics for subjectivity in fake reviews:\")\n",
    "print(dataset[dataset['legit'] == False]['subjectivity'].describe())\n",
    "print(\"Statistics for subjectivity in legit reviews:\")\n",
    "dataset[dataset['legit'] == True]['subjectivity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fef710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute review lengths (characters) and word counts, then print means for fake vs legit\n",
    "dataset['char_len'] = dataset['review'].str.len()\n",
    "dataset['word_count'] = dataset['review'].str.split().str.len()\n",
    "\n",
    "mean_char_fake = dataset.loc[dataset['legit'] == False, 'char_len'].mean()\n",
    "mean_char_legit = dataset.loc[dataset['legit'] == True, 'char_len'].mean()\n",
    "mean_words_fake = dataset.loc[dataset['legit'] == False, 'word_count'].mean()\n",
    "mean_words_legit = dataset.loc[dataset['legit'] == True, 'word_count'].mean()\n",
    "\n",
    "print(f\"Mean review length (chars) - Fake: {mean_char_fake:.1f}, Legit: {mean_char_legit:.1f}\")\n",
    "print(f\"Mean review length (words) - Fake: {mean_words_fake:.1f}, Legit: {mean_words_legit:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5105318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot_with_outliers_legit_review_length = dataset[dataset['legit'] == True]['word_count']\n",
    "box_plot_with_outliers_fake_review_length = dataset[dataset['legit'] == False]['word_count']\n",
    "data_to_plot = [box_plot_with_outliers_legit_review_length, box_plot_with_outliers_fake_review_length]\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(data_to_plot, tick_labels=['Legit Reviews', 'Fake Reviews'])\n",
    "ax.set_title('Review Lengths (Word Count) Distribution')\n",
    "ax.set_ylabel('Word Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6239bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_review_sentence_lenght_char = dataset[dataset['legit'] == False]['char_len']\n",
    "legit_review_sentence_lenght_char = dataset[dataset['legit'] == True]['char_len']\n",
    "data_to_plot_char = [legit_review_sentence_lenght_char, fake_review_sentence_lenght_char]\n",
    "fig, ax = plt.subplots()            \n",
    "ax.boxplot(data_to_plot_char, tick_labels=['Legit Reviews', 'Fake Reviews'])\n",
    "ax.set_title('Review Lengths (Character Count) Distribution')\n",
    "ax.set_ylabel('Character Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6292bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_path = './data/yelp_reviews_with_features.csv'\n",
    "other_df = pd.read_csv(other_path)\n",
    "\n",
    "dataset['id_review'] = dataset['id_review'].astype(str)\n",
    "other_df['id_review'] = other_df['id_review'].astype(str)\n",
    "\n",
    "\n",
    "dup_main = dataset['id_review'].duplicated().sum()\n",
    "dup_other = other_df['id_review'].duplicated().sum()\n",
    "\n",
    "print(\"--- DUPLICATE CHECK ---\")\n",
    "print(f\"Duplicates in Main Dataset:    {dup_main}\")\n",
    "print(f\"Duplicates in Features File:   {dup_other}\")\n",
    "\n",
    "if dup_other > 0:\n",
    "    print(f\"FIXING: Removing {dup_other} duplicate IDs from the features file to prevent merge explosion.\")\n",
    "    other_df = other_df.drop_duplicates(subset=['id_review'], keep='first')\n",
    "else:\n",
    "    print(\"âœ… Features file is clean (no duplicates).\")\n",
    "\n",
    "\n",
    "print(\"--- MERGING ---\")\n",
    "print(f\"Rows before merge: {len(dataset)}\")\n",
    "\n",
    "cols_to_use = other_df.columns.difference(dataset.columns).tolist()\n",
    "cols_to_use.append('id_review') # We must include the ID\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    dataset, \n",
    "    other_df[cols_to_use], \n",
    "    on='id_review', \n",
    "    how='left',\n",
    "    validate='many_to_one' #\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Rows after merge:  {len(merged_df)}\")\n",
    "\n",
    "if len(merged_df) > len(dataset):\n",
    "    print(\"WARNING: Row count increased! Your main dataset has duplicates itself.\")\n",
    "elif len(merged_df) < len(dataset):\n",
    "    print(\"WARNING: Row count decreased! Something went wrong with the left join.\")\n",
    "else:\n",
    "    print(\"SUCCESS: Row count is perfectly preserved.\")\n",
    "\n",
    "merged_path = './data/yelp_reviews_merged_features.csv'\n",
    "merged_df.to_csv(merged_path, index=False)\n",
    "print(f\"Saved to {merged_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
