{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbb670ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16483fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = './data/yelp_reviews_merged_features.csv'\n",
    "try:\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "    print(f\"Dataset loaded with {len(df)} rows and {len(df.columns)} columns.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found. Make sure '{INPUT_FILE}' exists and was generated by the visualization file.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35575c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COL = 'legit'\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "ID_COL = 'id_review'\n",
    "TEXT_COL = 'review'\n",
    "cols_to_keep = [ID_COL, TEXT_COL, TARGET_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f18923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in df.columns if col not in cols_to_keep and df[col].dtype in ['int64', 'float64']]\n",
    "\n",
    "X = df[feature_cols]\n",
    "\n",
    "print(f\"\\nNumeric features selected for PCA: {X.shape[1]} columns.\")\n",
    "print(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f18b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_cols_impute = X.columns[X.isnull().any()].tolist()\n",
    "\n",
    "if nan_cols_impute:\n",
    "    print(f\"\\nPerforming median imputation for columns: {nan_cols_impute}\")\n",
    "    \n",
    "    medians = X[nan_cols_impute].median()\n",
    "    \n",
    "    X = X.fillna(medians)\n",
    "\n",
    "    if X.isnull().sum().sum() == 0:\n",
    "        print(\"Imputation completed successfully. No remaining NaN values.\")\n",
    "    else:\n",
    "        print(\"WARNING: There are still NaN values after imputation. Please check the data.\")\n",
    "else:\n",
    "    print(\"\\nNo NaN values found, proceeding with scaling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35b2630",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"\\nFeatures standardized (mean ~0, standard deviation ~1).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cabd9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all possible components to analyze explained variance\n",
    "pca_analysis = PCA(n_components=0.95)\n",
    "pca_analysis.fit_transform(X_scaled)\n",
    "print(pca_analysis.n_components_)\n",
    "\n",
    "# Cumulative explained variance\n",
    "explained_variance_ratio_cumsum = np.cumsum(pca_analysis.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605bd184",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(explained_variance_ratio_cumsum, marker='o', linestyle='--')\n",
    "plt.title('Cumulative Explained Variance per Principal Component')\n",
    "plt.xlabel('Number of Principal Components (k)')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.grid(True)\n",
    "\n",
    "# Choose a target (e.g. 95% of total variance)\n",
    "target_variance = 0.95\n",
    "plt.axhline(\n",
    "    y=target_variance,\n",
    "    color='r',\n",
    "    linestyle='-',\n",
    "    label=f'{int(target_variance*100)}% Target Variance'\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85257abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of components needed to reach the target variance\n",
    "try:\n",
    "    n_components_optimal = np.argmax(\n",
    "        explained_variance_ratio_cumsum >= target_variance\n",
    "    ) + 1\n",
    "except ValueError:\n",
    "    n_components_optimal = len(feature_cols)  # If not reached, use all components\n",
    "\n",
    "print(f\"\\nTarget: {int(target_variance*100)}% of explained variance.\")\n",
    "print(f\"{n_components_optimal} principal components (PCs) are required to reach this target.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc5a72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the final PCA with the selected number of components\n",
    "pca_final = PCA(n_components=n_components_optimal)\n",
    "X_pca = pca_final.fit_transform(X_scaled)\n",
    "\n",
    "# Convert PCA results into a DataFrame\n",
    "pca_cols = [f'PC{i+1}' for i in range(n_components_optimal)]\n",
    "X_pca_df = pd.DataFrame(\n",
    "    data=X_pca,\n",
    "    columns=pca_cols,\n",
    "    index=df.index\n",
    ")\n",
    "\n",
    "print(f\"\\nFeatures reduced from {len(feature_cols)} to {n_components_optimal} components.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdcd4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ID, text, target, and new Principal Components\n",
    "df_final_ml = pd.concat([df[cols_to_keep], X_pca_df], axis=1)\n",
    "\n",
    "# Save the final dataset\n",
    "OUTPUT_FILE = './data/yelp_reviews_ml_ready_pca.csv'\n",
    "os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)\n",
    "df_final_ml.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "print(f\"\\nFinal ML-ready dataset with {df_final_ml.shape[1]} columns saved to {OUTPUT_FILE}.\")\n",
    "print(\"Numeric features are now represented by Principal Components (PCs).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
