{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fea946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "dataset = pd.read_csv('./data/yelp_dataset_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34bf6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_reviews = dataset[dataset['legit'] == False]['review']\n",
    "legit_reviews = dataset[dataset['legit'] == True]['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c948db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_empty_reviews = fake_reviews[fake_reviews == '']\n",
    "legit_empty_reviews = legit_reviews[legit_reviews == '']\n",
    "print(f\"Number of fake empty reviews: {len(fake_empty_reviews)}\")\n",
    "print(f\"Number of legit empty reviews: {len(legit_empty_reviews)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f490576",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "fake_pos = []\n",
    "for doc in nlp.pipe(fake_reviews, disable=[\"ner\"]):\n",
    "    print(f\"Processing fake review {len(fake_pos)+1}/{len(fake_reviews)}\")\n",
    "    fake_pos.append([token.pos_ for token in doc])\n",
    "legit_pos = []\n",
    "for doc in nlp.pipe(legit_reviews, disable=[\"ner\"]):\n",
    "    print(f\"Processing legit review {len(legit_pos)+1}/{len(legit_reviews)}\")\n",
    "    legit_pos.append([token.pos_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a09daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# aggregate POS counts from fake_pos (list of lists)\n",
    "pos_counts = Counter()\n",
    "for seq in fake_pos:\n",
    "    pos_counts.update(seq)\n",
    "\n",
    "# convert to DataFrame for plotting (pd is already imported)\n",
    "pos_df = pd.DataFrame(pos_counts.items(), columns=['pos', 'count']).sort_values('count', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=pos_df, x='pos', y='count', order=pos_df['pos'])\n",
    "plt.title('POS tag counts in fake reviews')\n",
    "plt.xlabel('POS tag')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77771bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate POS counts from legit_pos (list of lists)\n",
    "pos_counts_legit = Counter()\n",
    "for seq in legit_pos:\n",
    "    pos_counts_legit.update(seq)\n",
    "\n",
    "# convert to DataFrame for plotting (pd, sns, plt, Counter are already available)\n",
    "pos_df_legit = pd.DataFrame(pos_counts_legit.items(), columns=['pos', 'count']).sort_values('count', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=pos_df_legit, x='pos', y='count', order=pos_df_legit['pos'])\n",
    "plt.title('POS tag counts in legit reviews')\n",
    "plt.xlabel('POS tag')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f0c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "legit_pronouns = [pos_seq.count('PRON') for pos_seq in legit_pos]\n",
    "fake_pronouns = [pos_seq.count('PRON') for pos_seq in fake_pos]\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(legit_pronouns, label='Legit Reviews', fill=True\n",
    "              , color='blue', alpha=0.5)\n",
    "sns.kdeplot(fake_pronouns, label='Fake Reviews', fill=True\n",
    "              , color='red', alpha=0.5)\n",
    "plt.title('Distribution of Pronoun Counts in Reviews')\n",
    "plt.xlabel('Number of Pronouns')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141593e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "legit_top_5_words_no_pron_spacy = Counter()\n",
    "for pos_seq, review in zip(legit_pos, legit_reviews):\n",
    "    words = review.split()\n",
    "    for pos, word in zip(pos_seq, words):\n",
    "        if pos != 'PRON':\n",
    "            legit_top_5_words_no_pron_spacy.update([word.lower()])\n",
    "fake_top_5_words_no_pron_spacy = Counter()\n",
    "for pos_seq, review in zip(fake_pos, fake_reviews):\n",
    "    words = review.split()\n",
    "    for pos, word in zip(pos_seq, words):\n",
    "        if pos != 'PRON':\n",
    "            fake_top_5_words_no_pron_spacy.update([word.lower()])\n",
    "print(\"Top 5 words in legit reviews (excluding pronouns):\")\n",
    "print(legit_top_5_words_no_pron_spacy.most_common(5))  \n",
    "print(\"Top 5 words in fake reviews (excluding pronouns):\")\n",
    "print(fake_top_5_words_no_pron_spacy.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f57615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find legit reviews that are exact duplicates (copied & pasted)\n",
    "legit_df = dataset[dataset['legit'] == True].copy()\n",
    "\n",
    "# count occurrences of each review text among legit reviews\n",
    "dup_counts_legit = legit_df['review'].value_counts()\n",
    "\n",
    "# texts that appear more than once\n",
    "dup_texts_legit = dup_counts_legit[dup_counts_legit > 1].index\n",
    "\n",
    "# DataFrame with all occurrences of duplicated legit reviews and a column with the duplicate count\n",
    "copied_and_pasted_legit_reviews = legit_df[legit_df['review'].isin(dup_texts_legit)].assign(\n",
    "    duplicate_count=lambda d: d['review'].map(dup_counts_legit)\n",
    ")\n",
    "\n",
    "# summary info\n",
    "print(f\"Unique duplicated legit review texts: {len(dup_texts_legit)}\")\n",
    "print(f\"Total legit review rows that are duplicates: {len(copied_and_pasted_legit_reviews)}\")\n",
    "\n",
    "# show the most frequent duplicated texts (top 10) and preview the duplicated rows\n",
    "print(\"\\nTop duplicated legit review texts (text -> count):\")\n",
    "print(dup_counts_legit[dup_counts_legit > 1].head(10))\n",
    "\n",
    "copied_and_pasted_legit_reviews.sort_values('duplicate_count', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b55d2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df  = dataset[dataset['legit'] == False].copy()\n",
    "fake_dup_counts = fake_df['review'].value_counts()\n",
    "fake_dup_texts = fake_dup_counts[fake_dup_counts > 1].index\n",
    "copied_and_pasted_fake_reviews = fake_df[fake_df['review'].isin(fake_dup_texts)].assign(\n",
    "    duplicate_count=lambda d: d['review'].map(fake_dup_counts)\n",
    ")\n",
    "print(f\"Unique duplicated fake review texts: {len(fake_dup_texts)}\")\n",
    "print(f\"Total fake review rows that are duplicates: {len(copied_and_pasted_fake_reviews)}\")\n",
    "print(\"\\nTop duplicated fake review texts (text -> count):\")\n",
    "print(fake_dup_counts[fake_dup_counts > 1].head(10))\n",
    "copied_and_pasted_fake_reviews.sort_values('duplicate_count', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844be100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdescriptives as td\n",
    "\n",
    "readability_df = td.extract_metrics(\n",
    "    text=fake_reviews,          \n",
    "    spacy_model=\"en_core_web_sm\",     \n",
    "    metrics=[\"readability\"]              \n",
    ")\n",
    "\n",
    "\n",
    "fake_reviews = fake_reviews.join(readability_df.drop(columns=[\"text\"]))\n",
    "\n",
    "print(\"Legit reviews readbilty mean from textdescriptives:\")\n",
    "print(fake_reviews[\"readability\"].mean())\n",
    "\n",
    "\n",
    "print(fake_reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032ac7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdescriptives as td\n",
    "\n",
    "readability_df = td.extract_metrics(\n",
    "    text=legit_reviews,          \n",
    "    spacy_model=\"en_core_web_sm\",     \n",
    "    metrics=[\"readability\"]              \n",
    ")\n",
    "\n",
    "\n",
    "legit_reviews = legit_reviews.join(readability_df.drop(columns=[\"text\"]))\n",
    "\n",
    "print(\"Legit reviews readbilty mean from textdescriptives:\")\n",
    "print(legit_reviews[\"readability\"].mean())\n",
    "\n",
    "print(legit_reviews.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
