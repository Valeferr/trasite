{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fea946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "dataset = pd.read_csv('./data/yelp_dataset_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34bf6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_reviews = dataset[dataset['legit'] == False]['review']\n",
    "legit_reviews = dataset[dataset['legit'] == True]['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c948db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_empty_reviews = fake_reviews[fake_reviews == '']\n",
    "legit_empty_reviews = legit_reviews[legit_reviews == '']\n",
    "print(f\"Number of fake empty reviews: {len(fake_empty_reviews)}\")\n",
    "print(f\"Number of legit empty reviews: {len(legit_empty_reviews)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f490576",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "fake_pos = []\n",
    "fake_info_row = []\n",
    "for doc in nlp.pipe(fake_reviews):\n",
    "    print(f\"Processing fake review {len(fake_pos)+1}/{len(fake_reviews)}\")\n",
    "    fake_pos.append([token.pos_ for token in doc])\n",
    "    fake_info_row.append(doc)\n",
    "legit_pos = []\n",
    "legit_info_row = []\n",
    "for doc in nlp.pipe(legit_reviews):\n",
    "    print(f\"Processing legit review {len(legit_pos)+1}/{len(legit_reviews)}\")\n",
    "    legit_pos.append([token.pos_ for token in doc])\n",
    "    legit_info_row.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a09daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# aggregate POS counts from fake_pos (list of lists)\n",
    "pos_counts = Counter()\n",
    "for seq in fake_pos:\n",
    "    pos_counts.update(seq)\n",
    "\n",
    "# convert to DataFrame for plotting (pd is already imported)\n",
    "pos_df = pd.DataFrame(pos_counts.items(), columns=['pos', 'count']).sort_values('count', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=pos_df, x='pos', y='count', order=pos_df['pos'])\n",
    "plt.title('POS tag counts in fake reviews')\n",
    "plt.xlabel('POS tag')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77771bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate POS counts from legit_pos (list of lists)\n",
    "pos_counts_legit = Counter()\n",
    "for seq in legit_pos:\n",
    "    pos_counts_legit.update(seq)\n",
    "\n",
    "# convert to DataFrame for plotting (pd, sns, plt, Counter are already available)\n",
    "pos_df_legit = pd.DataFrame(pos_counts_legit.items(), columns=['pos', 'count']).sort_values('count', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=pos_df_legit, x='pos', y='count', order=pos_df_legit['pos'])\n",
    "plt.title('POS tag counts in legit reviews')\n",
    "plt.xlabel('POS tag')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d9b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_pos_pie_plot_percentages = pos_df.copy()\n",
    "total_fake_pos = fake_pos_pie_plot_percentages['count'].sum()\n",
    "fake_pos_pie_plot_percentages['percentage'] = fake_pos_pie_plot_percentages['count'] / total_fake_pos * 100\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(fake_pos_pie_plot_percentages['percentage'], labels=fake_pos_pie_plot_percentages['pos'], autopct='%1.1f%%', startangle=140)\n",
    "plt.title('POS tag distribution in fake reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "legit_pos_pie_plot_percentages = pos_df_legit.copy()\n",
    "total_legit_pos = legit_pos_pie_plot_percentages['count'].sum()\n",
    "legit_pos_pie_plot_percentages['percentage'] = legit_pos_pie_plot_percentages['count'] / total_legit_pos * 100\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(legit_pos_pie_plot_percentages['percentage'], labels=legit_pos_pie_plot_percentages['pos'], autopct='%1.1f%%', startangle=140)\n",
    "plt.title('POS tag distribution in legit reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f0c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "legit_pronouns = [pos_seq.count('PRON') for pos_seq in legit_pos]\n",
    "fake_pronouns = [pos_seq.count('PRON') for pos_seq in fake_pos]\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(legit_pronouns, label='Legit Reviews', fill=True\n",
    "              , color='blue', alpha=0.5)\n",
    "sns.kdeplot(fake_pronouns, label='Fake Reviews', fill=True\n",
    "              , color='red', alpha=0.5)\n",
    "plt.title('Distribution of Pronoun Counts in Reviews')\n",
    "plt.xlabel('Number of Pronouns')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b7574",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_pronoun_counts = Counter()\n",
    "for doc in fake_info_row:\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'PRON':\n",
    "            fake_pronoun_counts[token.text.lower()] += 1\n",
    "\n",
    "print(\"Most common pronouns in fake reviews:\")\n",
    "print(fake_pronoun_counts.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee51ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_pronoun_counts = Counter()\n",
    "for doc in legit_info_row:\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'PRON':\n",
    "            real_pronoun_counts[token.text.lower()] += 1\n",
    "print(\"Most common pronouns in legit reviews:\")\n",
    "print(real_pronoun_counts.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141593e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "legit_top_5_words_no_pron_only_nouns_from_legit_reviews = []\n",
    "for doc in legit_info_row:\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'NOUN':\n",
    "            legit_top_5_words_no_pron_only_nouns_from_legit_reviews.append(token.text.lower())\n",
    "legit_noun_counts = Counter(legit_top_5_words_no_pron_only_nouns_from_legit_reviews)\n",
    "print(\"Most common nouns in legit reviews:\")\n",
    "print(legit_noun_counts.most_common(10))\n",
    "fake_top_5_words_no_pron_only_nouns_from_fake_reviews = []\n",
    "for doc in fake_info_row:\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'NOUN':\n",
    "            fake_top_5_words_no_pron_only_nouns_from_fake_reviews.append(token.text.lower())\n",
    "fake_noun_counts = Counter(fake_top_5_words_no_pron_only_nouns_from_fake_reviews)\n",
    "print(\"Most common nouns in fake reviews:\")\n",
    "print(fake_noun_counts.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f57615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find legit reviews that are exact duplicates (copied & pasted)\n",
    "legit_df = dataset[dataset['legit'] == True].copy()\n",
    "\n",
    "# count occurrences of each review text among legit reviews\n",
    "dup_counts_legit = legit_df['review'].value_counts()\n",
    "\n",
    "# texts that appear more than once\n",
    "dup_texts_legit = dup_counts_legit[dup_counts_legit > 1].index\n",
    "\n",
    "# DataFrame with all occurrences of duplicated legit reviews and a column with the duplicate count\n",
    "copied_and_pasted_legit_reviews = legit_df[legit_df['review'].isin(dup_texts_legit)].assign(\n",
    "    duplicate_count=lambda d: d['review'].map(dup_counts_legit)\n",
    ")\n",
    "\n",
    "# summary info\n",
    "print(f\"Unique duplicated legit review texts: {len(dup_texts_legit)}\")\n",
    "print(f\"Total legit review rows that are duplicates: {len(copied_and_pasted_legit_reviews)}\")\n",
    "\n",
    "# show the most frequent duplicated texts (top 10) and preview the duplicated rows\n",
    "print(\"\\nTop duplicated legit review texts (text -> count):\")\n",
    "print(dup_counts_legit[dup_counts_legit > 1].head(10))\n",
    "\n",
    "copied_and_pasted_legit_reviews.sort_values('duplicate_count', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b55d2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df  = dataset[dataset['legit'] == False].copy()\n",
    "fake_dup_counts = fake_df['review'].value_counts()\n",
    "fake_dup_texts = fake_dup_counts[fake_dup_counts > 1].index\n",
    "copied_and_pasted_fake_reviews = fake_df[fake_df['review'].isin(fake_dup_texts)].assign(\n",
    "    duplicate_count=lambda d: d['review'].map(fake_dup_counts)\n",
    ")\n",
    "print(f\"Unique duplicated fake review texts: {len(fake_dup_texts)}\")\n",
    "print(f\"Total fake review rows that are duplicates: {len(copied_and_pasted_fake_reviews)}\")\n",
    "print(\"\\nTop duplicated fake review texts (text -> count):\")\n",
    "print(fake_dup_counts[fake_dup_counts > 1].head(10))\n",
    "copied_and_pasted_fake_reviews.sort_values('duplicate_count', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844be100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdescriptives as td\n",
    "\n",
    "readability_df = td.extract_metrics(\n",
    "    text=fake_reviews,          \n",
    "    spacy_model=\"en_core_web_sm\",     \n",
    "    metrics=[\"readability\"]              \n",
    ")\n",
    "\n",
    "\n",
    "print(readability_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032ac7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdescriptives as td\n",
    "\n",
    "readability_df = td.extract_metrics(\n",
    "    text=legit_reviews,          \n",
    "    spacy_model=\"en_core_web_sm\",     \n",
    "    metrics=[\"readability\"]              \n",
    ")\n",
    "\n",
    "\n",
    "print(readability_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de6190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "legit_review_verb_all_tense_percentages_per_sentence = []\n",
    "for doc in legit_info_row:\n",
    "    total_sentences = len(list(doc.sents))\n",
    "    if total_sentences == 0:\n",
    "        legit_review_verb_all_tense_percentages_per_sentence.append(0)\n",
    "        continue\n",
    "    verb_count = sum(1 for token in doc if token.pos_ == 'VERB')\n",
    "    percentage_per_sentence = verb_count / total_sentences * 100\n",
    "    legit_review_verb_all_tense_percentages_per_sentence.append(percentage_per_sentence)\n",
    "fake_review_verb_all_tense_percentages_per_sentence = []\n",
    "for doc in fake_info_row:\n",
    "    total_sentences = len(list(doc.sents))\n",
    "    if total_sentences == 0:\n",
    "        fake_review_verb_all_tense_percentages_per_sentence.append(0)\n",
    "        continue\n",
    "    verb_count = sum(1 for token in doc if token.pos_ == 'VERB')\n",
    "    percentage_per_sentence = verb_count / total_sentences * 100\n",
    "    fake_review_verb_all_tense_percentages_per_sentence.append(percentage_per_sentence)\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(legit_review_verb_all_tense_percentages_per_sentence, label='Legit Reviews', fill=True\n",
    "              , color='blue', alpha=0.5)   \n",
    "sns.kdeplot(fake_review_verb_all_tense_percentages_per_sentence, label='Fake Reviews', fill=True\n",
    "              , color='red', alpha=0.5)\n",
    "plt.title('Distribution of Verb Counts per Sentence in Reviews')\n",
    "plt.xlabel('Percentage of Verbs per Sentence')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "mean_legit_verbs_per_sentence = sum(legit_review_verb_all_tense_percentages_per_sentence) / len(legit_review_verb_all_tense_percentages_per_sentence)\n",
    "mean_fake_verbs_per_sentence = sum(fake_review_verb_all_tense_percentages_per_sentence) / len(fake_review_verb_all_tense_percentages_per_sentence)\n",
    "print(f\"Mean percentage of verbs per sentence in legit reviews: {mean_legit_verbs_per_sentence}\")\n",
    "print(f\"Mean percentage of verbs per sentence in fake reviews: {mean_fake_verbs_per_sentence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aed571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "legit_review_punctuaction_marks_type_per_sentence = []\n",
    "for doc in legit_info_row:\n",
    "    punctuation_marks = [token.text for token in doc if token.is_punct]\n",
    "    legit_review_punctuaction_marks_type_per_sentence.append(punctuation_marks)\n",
    "fake_review_punctuaction_marks_type_per_sentence = []\n",
    "for doc in fake_info_row:\n",
    "    punctuation_marks = [token.text for token in doc if token.is_punct]\n",
    "    fake_review_punctuaction_marks_type_per_sentence.append(punctuation_marks)\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot([len(punctuations) for punctuations in legit_review_punctuaction_marks_type_per_sentence], label='Legit Reviews', fill=True\n",
    "              , color='blue', alpha=0.5)    \n",
    "sns.kdeplot([len(punctuations) for punctuations in fake_review_punctuaction_marks_type_per_sentence], label='Fake Reviews', fill=True\n",
    "                , color='red', alpha=0.5)\n",
    "plt.title('Distribution of Punctuation Marks per Review')\n",
    "plt.xlabel('Number of Punctuation Marks')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "mean_legit_punctuation_marks = sum(len(punctuations) for punctuations in legit_review_punctuaction_marks_type_per_sentence) / len(legit_review_punctuaction_marks_type_per_sentence)\n",
    "mean_fake_punctuation_marks = sum(len(punctuations) for punctuations in fake_review_punctuaction_marks_type_per_sentence) / len(fake_review_punctuaction_marks_type_per_sentence)\n",
    "print(f\"Mean number of punctuation marks in legit reviews: {mean_legit_punctuation_marks}\")\n",
    "print(f\"Mean number of punctuation marks in fake reviews: {mean_fake_punctuation_marks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5165d05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "legit_review_money_mentions_percentages = []\n",
    "for doc in legit_info_row:\n",
    "    money_count = sum(1 for token in doc if token.pos_ == 'NUM' and ('$' in token.text or 'dollar' in token.text.lower()))\n",
    "    total_tokens = len(doc)\n",
    "    if total_tokens == 0:\n",
    "        legit_review_money_mentions_percentages.append(0)\n",
    "        continue\n",
    "    percentage = money_count / total_tokens * 100\n",
    "    legit_review_money_mentions_percentages.append(percentage)\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(legit_review_money_mentions_percentages, label='Legit Reviews', fill=True\n",
    "              , color='blue', alpha=0.5)\n",
    "plt.title('Distribution of Money Mentions Percentage in Legit Reviews')\n",
    "plt.xlabel('Percentage of Money Mentions')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fake_review_money_mentions_percentages = []\n",
    "for doc in fake_info_row:\n",
    "    money_count = sum(1 for token in doc if token.pos_ == 'NUM' and ('$' in token.text or 'dollar' in token.text.lower()))\n",
    "    total_tokens = len(doc)\n",
    "    if total_tokens == 0:\n",
    "        fake_review_money_mentions_percentages.append(0)\n",
    "        continue\n",
    "    percentage = money_count / total_tokens * 100\n",
    "    fake_review_money_mentions_percentages.append(percentage)   \n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(fake_review_money_mentions_percentages, label='Fake Reviews', fill=True\n",
    "                , color='red', alpha=0.5)\n",
    "plt.title('Distribution of Money Mentions Percentage in Fake Reviews')\n",
    "plt.xlabel('Percentage of Money Mentions')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "mean_legit_money_mentions = sum(legit_review_money_mentions_percentages) / len(legit_review_money_mentions_percentages)\n",
    "mean_fake_money_mentions = sum(fake_review_money_mentions_percentages) / len(fake_review_money_mentions_percentages)\n",
    "print(f\"Mean percentage of money mentions in legit reviews: {mean_legit_money_mentions}\")\n",
    "print(f\"Mean percentage of money mentions in fake reviews: {mean_fake_money_mentions}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b2eed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_review_agreement_words_counts = []\n",
    "for doc in fake_info_row:\n",
    "    agreement_words = [token.text.lower() for token in doc if token.text.lower() in ['agree', 'agreed', 'agreeing', 'agreement', 'agreeable', 'agrees']]\n",
    "    fake_review_agreement_words_counts.append(len(agreement_words))\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(fake_review_agreement_words_counts, label='Fake Reviews', fill=True\n",
    "                , color='red', alpha=0.5)\n",
    "plt.title('Distribution of Agreement Words Counts in Fake Reviews')\n",
    "plt.xlabel('Number of Agreement Words')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "legit_review_agreement_words_counts = []\n",
    "for doc in legit_info_row:\n",
    "    agreement_words = [token.text.lower() for token in doc if token.text.lower() in ['agree', 'agreed', 'agreeing', 'agreement', 'agreeable', 'agrees']]\n",
    "    legit_review_agreement_words_counts.append(len(agreement_words))\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(legit_review_agreement_words_counts, label='Legit Reviews',\n",
    "                 color='blue', alpha=0.5)\n",
    "plt.title('Distribution of Agreement Words Counts in Legit Reviews')\n",
    "plt.xlabel('Number of Agreement Words')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "mean_fake_agreement_words = sum(fake_review_agreement_words_counts) / len(fake_review_agreement_words_counts)\n",
    "mean_legit_agreement_words = sum(legit_review_agreement_words_counts) / len(legit_review_agreement_words_counts)\n",
    "print(f\"Mean number of agreement words in fake reviews: {mean_fake_agreement_words}\")\n",
    "print(f\"Mean number of agreement words in legit reviews: {mean_legit_agreement_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495b58bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "all_docs = list(legit_info_row) + list(fake_info_row)\n",
    "\n",
    "pos_tags = sorted({token.pos_ for doc in all_docs for token in doc})\n",
    "punct_types = sorted({token.text for doc in all_docs for token in doc if token.is_punct})\n",
    "all_tenses = sorted({\n",
    "    tense\n",
    "    for doc in all_docs\n",
    "    for token in doc\n",
    "    if token.pos_ == 'VERB'\n",
    "    for tense in token.morph.get('Tense')\n",
    "})\n",
    "\n",
    "punct_types_set = set(punct_types)\n",
    "all_tenses_set = set(all_tenses)\n",
    "\n",
    "\n",
    "feature_cols = []\n",
    "feature_cols.extend(['money_count', 'money_ratio_sent'])\n",
    "feature_cols.extend(['pronoun_count', 'pronoun_ratio_sent'])\n",
    "feature_cols.extend(['verb_count', 'verb_ratio_sent'])\n",
    "\n",
    "for tense in all_tenses:\n",
    "    feature_cols.extend([f'verb_tense_{tense}_count', f'verb_tense_{tense}_ratio_sent'])\n",
    "for tag in pos_tags:\n",
    "    feature_cols.extend([f'pos_{tag}_count', f'pos_{tag}_ratio_sent'])\n",
    "for sym in punct_types:\n",
    "    safe_sym = sym.replace(' ', '_')\n",
    "    feature_cols.extend([f'punct_{safe_sym}_count', f'punct_{safe_sym}_ratio_sent'])\n",
    "\n",
    "\n",
    "def extract_doc_features_fast(doc):\n",
    "    total_counts = defaultdict(int)\n",
    "    ratio_sums = defaultdict(float)\n",
    "    \n",
    "    sents = list(doc.sents)\n",
    "    \n",
    "    valid_sent_count = 0\n",
    "    \n",
    "    for sent in sents:\n",
    "        # Filter tokens once per sentence\n",
    "        tokens = [t for t in sent if not t.is_space]\n",
    "        sent_len = len(tokens)\n",
    "        \n",
    "        if sent_len == 0:\n",
    "            continue\n",
    "            \n",
    "        valid_sent_count += 1\n",
    "        inv_sent_len = 1.0 / sent_len\n",
    "        \n",
    "        # Local counters for this specific sentence\n",
    "        sent_counts = defaultdict(int)\n",
    "        \n",
    "        for t in tokens:\n",
    "            # --- POS Tags ---\n",
    "            # We use the raw tag directly\n",
    "            sent_counts[f'pos_{t.pos_}'] += 1\n",
    "            \n",
    "            # --- Punctuation ---\n",
    "            if t.is_punct and t.text in punct_types_set:\n",
    "                safe_sym = t.text.replace(' ', '_')\n",
    "                sent_counts[f'punct_{safe_sym}'] += 1\n",
    "            \n",
    "            # --- Verbs & Tenses ---\n",
    "            if t.pos_ == 'VERB':\n",
    "                sent_counts['verb'] += 1\n",
    "                tenses = t.morph.get('Tense')\n",
    "                for tense in tenses:\n",
    "                    if tense in all_tenses_set:\n",
    "                        sent_counts[f'verb_tense_{tense}'] += 1\n",
    "            \n",
    "            # --- Money ---\n",
    "            if t.pos_ == 'NUM' and ('$' in t.text or 'dollar' in t.text.lower()):\n",
    "                sent_counts['money'] += 1\n",
    "                \n",
    "            # --- Pronouns ---\n",
    "            if t.pos_ == 'PRON':\n",
    "                sent_counts['pronoun'] += 1\n",
    "\n",
    "        # End of Token Loop: Update Global Accumulators\n",
    "        for key, count in sent_counts.items():\n",
    "            total_counts[key] += count\n",
    "            ratio_sums[key] += (count * inv_sent_len)\n",
    "\n",
    "    # 4. Final Formatting\n",
    "    if valid_sent_count == 0:\n",
    "        return {}\n",
    "\n",
    "    # Merge counts and calculated average ratios into one dictionary\n",
    "    features = {}\n",
    "    \n",
    "    for key, count in total_counts.items():\n",
    "        features[f'{key}_count'] = count\n",
    "        features[f'{key}_ratio_sent'] = ratio_sums[key] / valid_sent_count\n",
    "        \n",
    "    return features\n",
    "\n",
    "# 5. Build DataFrames\n",
    "print(\"Extracting features...\")\n",
    "legit_features = [extract_doc_features_fast(doc) for doc in legit_info_row]\n",
    "fake_features = [extract_doc_features_fast(doc) for doc in fake_info_row]\n",
    "\n",
    "\n",
    "legit_features_df = pd.DataFrame(legit_features, index=legit_reviews.index).reindex(columns=feature_cols, fill_value=0.0)\n",
    "fake_features_df = pd.DataFrame(fake_features, index=fake_reviews.index).reindex(columns=feature_cols, fill_value=0.0)\n",
    "\n",
    "features_df = pd.concat([legit_features_df, fake_features_df]).sort_index()\n",
    "\n",
    "# Attach review text and label, then sav \n",
    "final_df = dataset[['id_review', 'review', 'legit']].join(features_df)\n",
    "\n",
    "output_path = './data/yelp_reviews_with_features.csv'\n",
    "final_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved {len(final_df)} rows with {len(final_df.columns)} columns to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
